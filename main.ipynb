{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Print Start time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------------------------------------------\n",
            "Start-Time\n",
            "2024-03-22 01:01:17\n",
            "------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "print(\"------------------------------------------------\")\n",
        "print(\"Start-Time\")\n",
        "# print current time in format: 2019-10-03 13:10:00\n",
        "print(time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()))\n",
        "print(\"------------------------------------------------\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Does df-save-path exist: True\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "print(\"Does df-save-path exist:\", os.path.exists('data/augmented_train_dfs'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                    keyword  \\\n",
            "0                                       run   \n",
            "1                                   outside   \n",
            "2                          run, swim, climb   \n",
            "3                                      walk   \n",
            "4                                   outside   \n",
            "...                                     ...   \n",
            "1795                     pool, beach,  pool   \n",
            "1796                     outside , outdoors   \n",
            "1797                                Jogging   \n",
            "1798                  walk, swimming,  pool   \n",
            "1799  roller blade, outside , roller blades   \n",
            "\n",
            "                                                   text  label  \n",
            "0     21/m. I want to experience young love, but I'v...      0  \n",
            "1     Having issues talking to a girl whom I enjoyed...      0  \n",
            "2     Need some advice for free social activities. I...      0  \n",
            "3      I spoke to her today.. A few weeks ago I met ...      0  \n",
            "4     How to get over Social Anxiety?. Hello, The ot...      0  \n",
            "...                                                 ...    ...  \n",
            "1795   Social Anxiety: The Essentials. After looking...      3  \n",
            "1796   Eye contact. Being in public. I can't do it. ...      3  \n",
            "1797  If you look for the light, you will find it. I...      3  \n",
            "1798   I feel like my SA is ruining my life. Hi, I h...      3  \n",
            "1799  I got social anxiety trying to roller blade. S...      3  \n",
            "\n",
            "[1800 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('data/SMM4H_2024_Task3_Training_1800.csv', usecols=['keyword', 'text', 'label'])\n",
        "\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQTbkPUSp-Zk"
      },
      "source": [
        "## Clean text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "m6qh9SyUqAHJ"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    import re\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)\n",
        "    # Remove special characters and numbers\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    # Remove extra whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "df['text'] = df['text'].apply(clean_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7VTjkZOqH85"
      },
      "source": [
        "## Add Keywords to text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0ZEJR8U3Gih2"
      },
      "outputs": [],
      "source": [
        "df['text'] = df['text'] + \" Keywords: \" + df['keyword']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CXNHCTPGiBr"
      },
      "source": [
        "## Split data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "D7Rl76CeI-t7"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# First, split the data into a training set and a temporary set (which will be further split into validation and test sets)\n",
        "train_texts, temp_texts, y_train, temp_labels = train_test_split(df['text'], df['label'], test_size=0.4, random_state=42)\n",
        "\n",
        "# Next, split the temporary set into validation and test sets\n",
        "val_texts, test_texts, y_val, y_test = train_test_split(temp_texts, temp_labels, test_size=0.5, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cut Classes to X texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0Fgq27NJvF5",
        "outputId": "aed84b8f-48cf-4880-c98b-d7c908ff93ed"
      },
      "outputs": [],
      "source": [
        "# Create a DataFrame from the training texts and labels\n",
        "train_df = pd.DataFrame({'text': train_texts, 'label': y_train})\n",
        "\n",
        "# Sample 200 texts from each class (or as many as are available for classes with fewer than 200 examples)\n",
        "sampled_dfs = []\n",
        "for label in train_df['label'].unique():\n",
        "    class_sample_size = min(len(train_df[train_df['label'] == label]), 200)\n",
        "    sampled_dfs.append(train_df[train_df['label'] == label].sample(n=class_sample_size, random_state=42))\n",
        "\n",
        "# Concatenate the samples to create a balanced training DataFrame\n",
        "train_df = pd.concat(sampled_dfs, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# df_plot = balanced_train_df.copy()\n",
        "\n",
        "# label_mapping = {1: 'positive', 2: 'neutral', 3: 'negative', 0: 'unrelated'}\n",
        "# df_plot['label'] = df_plot['label'].map(label_mapping)\n",
        "\n",
        "# # Contar el número de publicaciones en cada categoría\n",
        "# class_counts = df_plot['label'].value_counts()\n",
        "# print(class_counts)\n",
        "\n",
        "# # Crear un gráfico de barras\n",
        "# plt.figure(figsize=(8, 6))\n",
        "# class_counts.plot(kind='bar')\n",
        "# plt.title('Distribución de clases')\n",
        "# plt.xlabel('Clase')\n",
        "# plt.ylabel('Número de publicaciones')\n",
        "# plt.xticks(rotation=0)\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Backtranslate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "backtranslate = False\n",
        "# Save the augmented training dataframe to a CSV file\n",
        "train_df_path = 'data/augmented_train_dfs/train_df_plus_backtranslated_class_1_3.csv'\n",
        "\n",
        "if backtranslate:\n",
        "\n",
        "    from utils import backtranslation\n",
        "\n",
        "    for label in {1, 3}:\n",
        "        print(f\"Backtranslating class {label}...\")\n",
        "        # Backtranslate and augment the data for underrepresented classes\n",
        "        selected_texts = train_df[train_df['label'] == label]['text']\n",
        "        print(f\"length texts of label {label}\", len(selected_texts))\n",
        "        augmented_texts = backtranslation.backtranslate(selected_texts.to_list())\n",
        "        augmented_df = pd.DataFrame({'text': augmented_texts, 'label': [label] * len(augmented_texts)})\n",
        "        augmented_df.to_csv(f'data/augmented_train_dfs/backtranslated_class_{label}.csv', index=False)\n",
        "        train_df = pd.concat([train_df, augmented_df])\n",
        "\n",
        "    # Check the new class distribution after backtranslation\n",
        "    print(\"Class distribution after backtranslation:\", train_df['label'].value_counts())\n",
        "\n",
        "    train_df.to_csv(train_df_path, index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load train_df from csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # If we don't backtranslate, load the existing augmented training DataFrame\n",
        "# if not backtranslate:\n",
        "#     train_df = pd.read_csv(train_df_path)\n",
        "#     print(\"Class distribution:\", train_df['label'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Split train_df into texts and labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train texts balanced 0      i was just assaulted by a gang of teens so i w...\n",
            "1      a park down the sreet where people like to get...\n",
            "2      sharing my experience of social anxiety for th...\n",
            "3      im in the exact same situation i havent done a...\n",
            "4      friends to get over social anxiety hey i was w...\n",
            "                             ...                        \n",
            "563    going for a walk in the rain can be really nic...\n",
            "564    it depends what you mean by fast i think someo...\n",
            "565    obviously none of us are doctors here but it s...\n",
            "566    as someone who has suffered from social anxiet...\n",
            "567    hahaha i think about of the population thinks ...\n",
            "Name: text, Length: 568, dtype: object\n",
            "y_train balanced 0      2\n",
            "1      2\n",
            "2      2\n",
            "3      2\n",
            "4      2\n",
            "      ..\n",
            "563    1\n",
            "564    1\n",
            "565    1\n",
            "566    1\n",
            "567    1\n",
            "Name: label, Length: 568, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Now you can extract the texts and labels\n",
        "train_texts = train_df['text']\n",
        "print(\"Train texts balanced\", train_texts)\n",
        "y_train = train_df['label']\n",
        "print(\"y_train balanced\", y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'Series' object has no attribute 'append'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_54212\\3546211865.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfeed_forward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mfeed_forward\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_texts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_texts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_texts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32mc:\\Users\\l-e-o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6292\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6293\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6294\u001b[0m         \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6295\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6296\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'append'"
          ]
        }
      ],
      "source": [
        "from models import tune_transformer\n",
        "\n",
        "# model = 'DistilBert'\n",
        "model = 'RoBERTa'\n",
        "\n",
        "print(\"------------------------------------\")\n",
        "print(\"Model:\", model)\n",
        "print(\"------------------------------------\")\n",
        "\n",
        "if model == 'DistilBert':\n",
        "    tune_transformer.run('distilbert-base-uncased', train_texts, val_texts, test_texts, y_train, y_val, y_test)\n",
        "elif model == 'RoBERTa':\n",
        "    tune_transformer.run('roberta-base', train_texts, val_texts, test_texts, y_train, y_val, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Print End Time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "print(\"------------------------------------------------\")\n",
        "print(\"End-Time\")\n",
        "# print current time in format: 2019-10-03 13:10:00\n",
        "print(time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()))\n",
        "print(\"------------------------------------------------\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
